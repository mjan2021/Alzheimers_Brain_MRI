{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d93ba66d-0194-43ee-a7b9-3dbd4c0912fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mustafa/miniforge3/envs/fedfinal/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os, copy, random, sys\n",
    "import itertools\n",
    "import io\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split, SubsetRandomSampler, ConcatDataset\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "sys.path.insert(0,'/Users/mustafa/Desktop/GitHub/SkinCancer/src')\n",
    "# from config import args_parser \n",
    "from models import *\n",
    "from dataset import SkinCancer\n",
    "\n",
    "# from sklearn.utils import class_weight\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3896eaf-329b-4d6f-95dd-c48ba70a4548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "       cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "       class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "    \n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45,fontsize=8,horizontalalignment='right')\n",
    "    plt.yticks(tick_marks, class_names,fontsize=8)\n",
    "    \n",
    "    # Normalize the confusion matrix.\n",
    "    # cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "    \n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color,fontsize=7)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86f7a8fc-cda4-42c1-9a84-a391f1b647eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,device,dataloader,loss_fn,optimizer):\n",
    "    train_loss,train_correct=0.0,0\n",
    "    model.train()\n",
    "    for images, labels in dataloader:\n",
    "\n",
    "        images,labels = images.to(device),labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = loss_fn(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        scores, predictions = torch.max(output.data, 1)\n",
    "        train_correct += (predictions == labels).sum().item()\n",
    "\n",
    "    return train_loss,train_correct\n",
    "  \n",
    "def valid_epoch(model,device,dataloader,loss_fn):\n",
    "    valid_loss, val_correct = 0.0, 0\n",
    "    model.eval()\n",
    "    y_true,y_pred = [], []\n",
    "    for images, labels in dataloader:\n",
    "\n",
    "        images,labels = images.to(device),labels.to(device)\n",
    "        output = model(images)\n",
    "        loss=loss_fn(output,labels)\n",
    "        valid_loss+=loss.item()*images.size(0)\n",
    "        scores, predictions = torch.max(output.data,1)\n",
    "        \n",
    "        val_correct+=(predictions == labels).sum().item()\n",
    "        \n",
    "\n",
    "        \n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "        \n",
    "        \n",
    "    # y_true = np.array(y_true)\n",
    "    # y_pred = np.array(y_pred)\n",
    "    # cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    \n",
    "\n",
    "    return valid_loss,val_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da01025e-6f6f-4a8e-942b-9c3ad8d03381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inference(model,device,dataloader,loss_fn,class_names):\n",
    "                                                           \n",
    "    test_loss, test_correct = 0.0, 0\n",
    "    model.eval()\n",
    "    y_true,y_pred = [], [] # Use for Confusion Matrix\n",
    "    y_t,y_p = [], [] # Use for Metrics (f1, precision, recall)\n",
    "    for images, labels in dataloader:\n",
    "\n",
    "        images,labels = images.to(device),labels.to(device)\n",
    "        output = model(images)\n",
    "        loss=loss_fn(output,labels)\n",
    "        test_loss+=loss.item()*images.size(0)\n",
    "        scores, predictions = torch.max(output.data,1)\n",
    "        \n",
    "        test_correct+=(predictions == labels).sum().item()\n",
    "        \n",
    "\n",
    "        \n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "        \n",
    "        y_t.append(labels.cpu().numpy())\n",
    "        y_p.append(predictions.cpu().numpy())\n",
    "        \n",
    "        \n",
    "\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    cf_figure = plot_confusion_matrix(cf_matrix, class_names)\n",
    "    \n",
    "#     f_l = [f1_score(p, t, average='macro') for t,p in zip(y_t, y_p)]\n",
    "#     p_l = [precision_score(p, t, average='macro') for t,p in zip(y_t, y_p)]\n",
    "#     r_l = [recall_score(p, t, average='macro') for t,p in zip(y_t, y_p)]\n",
    "#     # auc_l = [roc_auc_score(p.cpu().numpy(), t.cpu().numpy(), multi_class='ovr') for t,p in zip(y_true,y_pred)]\n",
    "    \n",
    "#     f1_s = sum(f_l)/len(f_l)\n",
    "#     # print('f1:', f1_s)\n",
    "#     p_s = sum(p_l)/len(p_l)\n",
    "#     r_s = sum(r_l)/len(r_l)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # m_dict = pd.DataFrame({'F1_Score' : f1_s,\n",
    "    #       'Precision' : p_s, \n",
    "    #       'Recall' : r_s})\n",
    "    \n",
    "    \n",
    "    # metrics_table.add_data(f1_s,p_s,r_s)\n",
    "    \n",
    "    \n",
    "#     wandb.log({\"Testing-Confusion-Matrix\": wandb.plot.confusion_matrix(probs=None, y_true=y_true, preds = y_pred, class_names = class_names)})\n",
    "    \n",
    "#     wandb.log({\"Metrics-Table\": wandb.Table(columns=['F1_Score','Precision','Recall'], data=[[f1_s, p_s, r_s]])})\n",
    "    \n",
    "\n",
    "    return test_loss,test_correct, cf_figure, cf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bb86cd1-b6cf-4714-95fe-93044beb2dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k=5\n",
    "# splits=KFold(n_splits=k,shuffle=True,random_state=42)\n",
    "\n",
    "\n",
    "# ======================= DATA ======================= #\n",
    "\n",
    "data_dir = '../data/HAM10k/HAM10000_images'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset = SkinCancer(data_dir, '../data/train.csv', transform=None)\n",
    "dataset_size = len(dataset)\n",
    "\n",
    "test_dataset = SkinCancer(data_dir, '../data/test.csv', transform=None)\n",
    "\n",
    "\n",
    "\n",
    "# ======================= Model | Loss Function | Optimizer ======================= # \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09273563-8f30-46e9-9ea9-c1706159c819",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = efficientnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "813c03c2-213c-45aa-8df5-a215d163cb8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../models/EfficientNet_original_10Epochs.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea65423-c9a8-41f8-ba7c-a87eaa2247dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8787d20-f1fe-4b1a-b0e5-88711a36996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade8dae2-8c60-4ed1-bcef-f56832bf12c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a60abbd8-f3b3-4e0e-9f87-6c717da9ec94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Second Test\n",
    "# model.avgpool = Identity()\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.BatchNorm1d(num_features=1280),    \n",
    "    nn.Linear(1280, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.Linear(1280, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(num_features=512),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(512, 7),\n",
    "    )\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75c94264-0997-4e04-8209-d96875ab8d84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tune_layers = ['fc', 'classifier']\n",
    "\n",
    "# This function finetunes only fc layers \n",
    "# Another test would be to add new classifier and tune that\n",
    "def fine_tunemodel(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if not 'classifier' in name:\n",
    "            # if not 'classifier' in name:\n",
    "            param.requires_grad = False\n",
    "        # print(name, param.requires_grad)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1b1365-1fb1-466f-9d30-c075adb88110",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fine_tunemodel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f577cc-9192-4f97-b13b-4ed726701f08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5d4166d-6d12-4c03-99ff-bf2c0f711526",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adamax(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "batch_size = 16\n",
    "class_names = dataset.classes\n",
    "epochs=5\n",
    "\n",
    "logger = SummaryWriter(log_dir = f'../tb_logs/{model._get_name()}/original_finetuning_classifier_R3_{epochs}Epochs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e1c06d-a0a5-4020-afde-37853433b32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<----------Using MPS--------->\n",
      "Fold 0\n",
      "Model EfficientNet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ======================= Start ======================= #\n",
    "start_t = time.time() \n",
    "\n",
    "best_acc = 0.0\n",
    "\n",
    "step = 0\n",
    "k=5\n",
    "splits=KFold(n_splits=k,shuffle=True,random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# args.finetune = 'finetune' if args.finetune else 'transfer'\n",
    "\n",
    "fine_tune = True\n",
    "\n",
    "if os.name == 'posix' and torch.backends.mps.is_available(): # device is mac m1 chip\n",
    "    print(f\"<----------Using MPS--------->\")\n",
    "    device = 'mps'\n",
    "elif os.name == 'nt' and torch.cuda.is_available(): # device is windows with cuda\n",
    "    print(f'\"<----------Using CUDA--------->')\n",
    "    device = args.device\n",
    "else:\n",
    "    print(f'\"<----------Using CPU--------->')\n",
    "    device = 'cpu'\n",
    "\n",
    "\n",
    "# class_weights=class_weight.compute_class_weight('balanced',classes=np.unique(dataset.classes),y=np.array(dataset.classes_all))\n",
    "# class_weights=torch.FloatTensor(class_weights).to(device)\n",
    "#             # class_weights = class_weight.compute_class_weight('balanced',classes=np.unique(dataset.classes),y=self.df['dx'].to_numpy()),device='cuda')\n",
    "# criterion = nn.CrossEntropyLoss(weight = class_weights,reduction='mean') \n",
    "\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
    "\n",
    "    print('Fold {}'.format(fold))\n",
    "    print('Model {}'.format(model._get_name()))\n",
    "    # print('Wandb Run Name: {}'.format(wandb.run.name))\n",
    "\n",
    "\n",
    "    # model.load_state_dict(MODEL_WEIGHTS) # uncomment to start fresh for each fold\n",
    "\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(val_idx)\n",
    "\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler) # train, will change for each fold\n",
    "    val_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler) # validation \n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size) # hold out set, test once at the end of each fold\n",
    "\n",
    "\n",
    "\n",
    "# ======================= Train per fold ======================= #\n",
    "    for epoch in range(epochs):\n",
    "        step+=1\n",
    "        train_loss, train_correct = train_epoch(model,device,train_loader,criterion,optimizer)\n",
    "        val_loss, val_correct = valid_epoch(model,device,val_loader,criterion)\n",
    "        test_loss_epoch, test_acc_epoch, cf_figure, _ = test_inference(model,device,test_loader,criterion,class_names)\n",
    "        logger.add_figure(\"Confusion Matrix Epoch\", cf_figure, step)\n",
    "\n",
    "        train_loss = train_loss / len(train_loader.sampler)\n",
    "        train_acc = train_correct / len(train_loader.sampler) * 100\n",
    "        val_loss = val_loss / len(val_loader.sampler)\n",
    "        val_acc = val_correct / len(val_loader.sampler) * 100\n",
    "\n",
    "        print(f\"Epoch: {epoch}/{epochs},\\n AVG Training Loss:{train_loss} \\t Testing Loss{val_loss}\\nAVG Training Acc: {train_acc} % \\t Testing Acc {val_acc}\")\n",
    "\n",
    "\n",
    "        test_loss_epoch = test_loss_epoch / len(test_loader.sampler)\n",
    "        test_acc_epoch = test_acc_epoch / len(test_loader.sampler) * 100\n",
    "\n",
    "\n",
    "        # print(\"Epoch:{}/{}\\nAVG Training Loss:{:.3f} \\t Testing Loss:{:.3f}\\nAVG Training Acc: {:.2f} % \\t Testing Acc {:.2f} % \".format(epoch, args.epochs, train_loss,  val_loss, train_acc,  val_acc))\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "# ======================= Save per Epoch ======================= #\n",
    "\n",
    "        logger.add_scalars('Loss', {'train':train_loss,\n",
    "                                'val':val_loss,\n",
    "                                'test':test_loss_epoch}, step)\n",
    "\n",
    "        logger.add_scalars('Acc', {'train':train_acc,\n",
    "                                'val':val_acc,\n",
    "                                'test':test_acc_epoch}, step)\n",
    "\n",
    "\n",
    "\n",
    "        # ======================= Save model if new high accuracy ======================= #\n",
    "        if test_acc_epoch > best_acc:\n",
    "            print('#'*25)\n",
    "            print('New High Acc: ', test_acc_epoch)\n",
    "            print('#'*25)\n",
    "            best_acc = test_acc_epoch\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            torch.save(model.state_dict(), f'../models/{model._get_name()}_original_finetuning_{epochs}Epochs.pth')\n",
    "            \n",
    "\n",
    "            # Save Scripted Model \n",
    "            scripted_model = torch.jit.script(model)\n",
    "            torch.jit.save(scripted_model, f'../models/scripted_{model._get_name()}_original_finetuning_{epochs}Epochs.pt')\n",
    "\n",
    "        \n",
    "        if step == 10:\n",
    "            model =fine_tunemodel(model)\n",
    "            # lambda p: p.requires_grad, model.parameters()\n",
    "            optimizer = torch.optim.Adamax(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "            \n",
    "            print('FineTuning Stage')\n",
    "\n",
    "\n",
    "\n",
    "# ======================= Test Model on HOS ======================= #\n",
    "\n",
    "    test_loss, test_correct, cf_figure_fold, cf_matrix = test_inference(model,device,test_loader,criterion,class_names)\n",
    "\n",
    "    logger.add_figure(\"Confusion Matrix Fold\", cf_figure_fold, fold)\n",
    "\n",
    "    test_loss = test_loss / len(test_loader.sampler)\n",
    "    test_acc = test_correct / len(test_loader.sampler) * 100\n",
    "\n",
    "    np.save(f'../output_files/cf_matrix/{model._get_name()}_original_finetuning_classifier_Fold{fold}.npy', cf_matrix)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # print(\"Fold:{}/{}\\nTesting Loss:{:.3f} \\t Testing Acc:{:.3f}% \".format(fold,test_loss, test_acc))\n",
    "    # print(f\"Fold:{fold}\\nTesting Loss:{test_loss} \\t Testing Acc:{test_acc}%\")\n",
    "    # wandb.log({\"Fold Test\": {\"test_loss\" : test_loss,\n",
    "    #                          \"test_acc\" : test_acc}})\n",
    "\n",
    "    logger.add_scalar('Fold/Acc', test_acc, fold)\n",
    "    logger.add_scalar('Fold/Loss', test_loss, fold)\n",
    "\n",
    "\n",
    "# \n",
    "\n",
    "\n",
    "# ======================= Save model if new high accuracy ======================= #\n",
    "#     if test_acc > best_acc:\n",
    "#         print('#'*25)\n",
    "#         print('New High Acc: ', test_acc)\n",
    "#         print('#'*25)\n",
    "#         best_acc = test_acc\n",
    "#         best_model_wts = copy.deepcopy(model.state_dict())\n",
    "#         torch.save(model.state_dict(), f'../models/{model._get_name()}_{args.modality}_{args.finetune}_{args.epochs}Epochs.pth')\n",
    "\n",
    "#         # Save Scripted Model \n",
    "#         scripted_model = torch.jit.script(model)\n",
    "#         torch.jit.save(scripted_model, f'../models/scripted_{model._get_name()}_{args.modality}_{args.finetune}_{args.epochs}Epochs.pt')\n",
    "\n",
    "end_train = time.time()\n",
    "time_elapsed = start_t - end_train\n",
    "\n",
    "print(f'{model._get_name()} Training completed in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788516f7-d35a-4129-ad4a-4873f8a008e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipykernel\n",
    "ipython\n",
    "jupyter_client\n",
    "jupyter_core\n",
    "traitlets\n",
    "ipython_genutils"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
